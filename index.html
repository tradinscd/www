<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="description" content="Research website of Dustin Tran, a Ph.D.
  student at Columbia.">
  <meta name="author" content="Dustin Tran">
  <link rel="shortcut icon" href="/img/favicon.ico" type="image/x-icon">
  <title>Dustin Tran</title>

  <!-- CSS -->
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.1/css/bootstrap.min.css">
  <link href="http://maxcdn.bootstrapcdn.com/font-awesome/4.1.0/css/font-awesome.min.css" rel="stylesheet">
  <link rel="stylesheet" href="/css/main.css">

  <!-- HTML5 shim and Respond.js for IE8 support of HTML5 elements and media queries -->
  <!--[if lt IE 9]>
    <script src="https://oss.maxcdn.com/html5shiv/3.7.2/html5shiv.min.js"></script>
    <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
  <![endif]-->
</head>
<body>
  <div class="container">

    <div class="row" style="padding:20px">

       <div class="hidden-xs col-sm-3 col-md-2" id="sidebar" role="navigation" style="margin-top:180px">
        <hr>
        <ul class="nav nav-pills nav-stacked">
          <li><a href="#publications">Publications</a></li>
          <li><a href="blog">Blog</a></li>
        </ul>
      </div>

      <div class="col-xs-12 col-sm-9 col-md-9">

        <div class="row">
          <img src="img/photo-border.png" class="pull-left" style="margin:20px
          20px 20px 0; height:140px; width:140px; border-radius:100%"/>
          <h1>Dustin Tran</h1>
          <p class="lead">
            Research Scientist at Google Brain<br>
            trandustin@google.com
            <br>
            <a href="https://twitter.com/dustinvtran" class="icon">
              <i class="fa fa-twitter fa-lg"></i>
            </a>
            <a href="https://github.com/dustinvtran" class="icon">
              <i class="fa fa-github fa-lg"></i>
            </a>
            <a href="blog" class="icon blog">Blog</a>
          </p>
        </div>

        <hr>

        <div class="row">
          <p>
          I am a research scientist at
          <a href="https://ai.google/research/teams/brain">Google Brain</a>.
          I am broadly interested in advancing science and intelligence, and
          where the ideas involve probability, programs, and/or neural nets.
          </p>
          <p>
          I like to work simultaneously on fundamental research as well as
          systems to accelerate this research. In terms of systems, this
          includes
          <a href="https://github.com/google-research/google-research/tree/master/simple_probabilistic_programming">Edward2</a>
          for specifying probability models as programs,
          <a href="https://github.com/tensorflow/mesh">Mesh TensorFlow</a>
          for distributed computation, and
          <a href="https://github.com/tensorflow/tensor2tensor">Tensor2Tensor</a>
          for deep learning research.
          Previously, I was a Ph.D. student at Columbia advised by
          <a href="http://www.cs.columbia.edu/~blei/">David Blei</a>
          and <a href="http://www.stat.columbia.edu/~gelman/">Andrew
          Gelman</a>.
          I developed the original
          <a href="http://edwardlib.org">Edward</a>
          language and was a member of the
          <a href="http://mc-stan.org">Stan</a> development team.
          </p><p>
          Recently, I have been giving the following talk:
          </p>
          <ul>
            <li>
              <div class="btn-group-xs">
                <strong>What Might Deep Learners Learn From Probabilistic
                  Programming?</strong>
                <a href="/talks/Tran_Probabilistic_Programming.pdf"
                class="btn btn-default">Slides</a>
                <a href="https://www.youtube.com/watch?v=30FDdK2734I"
                class="btn btn-default">Video</a>
              </div>
            </li>
          </ul><p>
          <strong><a href="cv.pdf">Curriculum Vitae</a></strong>
          </p>
        </div>

        <div class="row">
          <h2><a name="publications"></a>Publications</h2>
          <hr>
          <h3>Preprints</h3>
          <p>
          Some of my work is available as
          <a href="http://arxiv.org/a/tran_d_1.html">preprints on arXiv</a>.
          </p>
          <p>
            <strong>Measuring calibration in deep learning</strong><br>
            How to evaluate accuracy of predicted probabilities.
            <br>
            Jeremy Nixon, Mike Dusenberry, Linchuan Zhang, Ghassen
            Jerfel, <strong>Dustin Tran</strong><br>
            <div class="btn-group-xs">
              <a href="https://arxiv.org/abs/1904.01685"
              class="btn btn-default">Paper</a>
            </div>
          </p>
          <p>
            <strong>Bayesian Layers: A module for neural network uncertainty</strong><br>
            A neural net-stylized primitive for distributions over functions.
            <br>
            <strong>Dustin Tran</strong>, Mike Dusenberry, Mark van
            der Wilk, Danijar Hafner<br>
            <div class="btn-group-xs">
              <a href="https://arxiv.org/abs/1812.03973"
              class="btn btn-default">Paper</a>
              <a href="/papers/TranDusenberryVanDerWilkHafner2018_poster.pdf"
              class="btn btn-default">Poster</a>
              <a href="https://github.com/tensorflow/tensor2tensor"
              class="btn btn-default">Code</a>
            </div>
          </p>
          <p>
           <strong>TensorFlow Distributions</strong><br>
           A backend for efficient, composable manipulation of
           probability distributions.
           <br>
           Joshua V. Dillon, Ian Langmore, <strong>Dustin
           Tran</strong>, Eugene Brevdo, Srinivas Vasudevan, Dave
           Moore, Brian Patton, Alex Alemi, Matt Hoffman, Rif A.
           Saurous<br>
           <div class="btn-group-xs">
             <a href="https://arxiv.org/abs/1711.10604"
             class="btn btn-default">Paper</a>
             <a href="/papers/DillonEtAl2018_poster.pdf"
             class="btn btn-default">Poster</a>
             <a href="https://github.com/tensorflow/probability"
             class="btn btn-default">Code</a>
           </div>
          </p>
          <p>
            <strong>Expectation propagation as a way of life: A
            framework for Bayesian inference on partitioned
            data</strong><br>
            How to distribute inference with massive data sets and how
            to combine inferences from many data sets.
            <br>
            Andrew Gelman, Aki Vehtari, Pasi Jylänki, Tuomas Sivula,
            <strong>Dustin Tran</strong>, Swupnil Sahai, Paul
            Blomstedt, John P. Cunningham, David Schiminovich,
            Christian Robert<br>
            <div class="btn-group-xs">
              <a href="https://arxiv.org/abs/1412.4869"
              class="btn btn-default">Paper</a>
            </div>
          </p>
          <p>
            <strong>Edward: A library for probabilistic modeling,
            inference, and criticism</strong><br>
            Everything and anything about probabilistic models.
            <br>
            <strong>Dustin Tran</strong>, Alp Kucukelbir, Adji B. Dieng,
            Maja Rudolph, Dawen Liang, David M. Blei<br>
            <div class="btn-group-xs">
              <a href="https://arxiv.org/abs/1610.09787"
              class="btn btn-default">Paper</a>
              <a href="http://edwardlib.org"
              class="btn btn-default">Website</a>
              <a href="/talks/Tran_Edward.pdf"
              class="btn btn-default">Slides</a>
            </div>
          </p>
          <p>
            <strong>Model criticism for Bayesian causal inference</strong><br>
            How to validate inferences from causal models.
            <br>
            <strong>Dustin Tran</strong>, Francisco J. R. Ruiz, Susan
            Athey, David M. Blei<br>
            <div class="btn-group-xs">
              <a href="http://arxiv.org/abs/1610.09037"
              class="btn btn-default">Paper</a>
            </div>
          </p>
          <p>
            <strong>Stochastic gradient descent methods for estimation with
            large data sets</strong><br>
            Fast and statistically efficient algorithms for
            generalized linear models and M-estimation.
            <br>
            <strong>Dustin Tran</strong>, Panos Toulis, Edoardo M.
            Airoldi<br>
            <em>Journal of Statistical Software</em>, To appear
            <div class="btn-group-xs">
              <a href="http://arxiv.org/abs/1509.06459"
              class="btn btn-default">Paper</a>
              <a href="https://github.com/airoldilab/sgd"
              class="btn btn-default">Code</a>
            </div>
          </p>
          <h3>2019</h3>
          <p>
           <strong>Reliable uncertainty estimates in deep neural
             networks using noise contrastive priors</strong><br>
           A prior for neural networks in data space.
           <br>
           Danijar Hafner, <strong>Dustin Tran</strong>, Alex Irpan,
           Timothy Lillicrap, James Davidson<br>
           <em>Uncertainty in Artificial Intelligence</em>, 2019
           <div class="btn-group-xs">
             <a href="https://arxiv.org/abs/1807.09289"
             class="btn btn-default">Paper</a>
             <a href="/papers/HafnerTranIrpanLillicrapDavidson2018_poster.pdf"
             class="btn btn-default">Poster</a>
             <a href="https://github.com/brain-research/ncp"
             class="btn btn-default">Code</a>
           </div>
          </p>
          <h3>2018</h3>
          <p>
           <strong>Simple, distributed, and accelerated probabilistic
           programming</strong><br>
           Probabilistic programs on TPUs.
           <br>
           <strong>Dustin Tran</strong>, Matthew D. Hoffman, Dave
           Moore, Christopher Suter, Srinivas Vasudevan, Alexey Radul,
           Matthew Johnson, Rif A. Saurous<br>
           <em>Neural Information Processing Systems</em>, 2018
           <div class="btn-group-xs">
             <a href="https://arxiv.org/abs/1811.02091"
             class="btn btn-default">Paper</a>
             <a href="/papers/TranHoffmanMooreSuterVasudevanRadulJohnsonSaurous2018_poster.pdf"
             class="btn btn-default">Poster</a>
             <a href="https://github.com/google-research/google-research/tree/master/simple_probabilistic_programming"
             class="btn btn-default">Code</a>
           </div>
          </p>
          <p>
           <strong>Autoconj: Recognizing and exploiting conjugacy
           without a domain-specific language</strong><br>
           The autointegrate analog of autodiff.
           <br>
           Matthew D. Hoffman, Matthew Johnson, <strong>Dustin
           Tran</strong><br>
           <em>Neural Information Processing Systems</em>, 2018
           <div class="btn-group-xs">
             <a href="https://papers.nips.cc/paper/8270-autoconj-recognizing-and-exploiting-conjugacy-without-a-domain-specific-language"
             class="btn btn-default">Paper</a>
             <a href="/papers/HoffmanJohnsonTran2018_poster.pdf"
             class="btn btn-default">Poster</a>
             <a href="https://github.com/google-research/autoconj"
             class="btn btn-default">Code</a>
           </div>
          </p>
          <p>
	   <strong>Mesh-TensorFlow: Deep learning for
	   supercomputers</strong><br>
           Model parallelism made easier.
           <br>
	   Noam Shazeer, Youlong Cheng, Niki Parmar, <strong>Dustin
           Tran</strong>, Ashish Vaswani, Penporn Koanantakool, Peter Hawkins,
	   HyoukJoong Lee, Mingsheng Hong, Cliff Young, Ryan Sepassi, Blake
           Hechtman<br>
           <em>Neural Information Processing Systems</em>, 2018
           <div class="btn-group-xs">
             <a href="https://arxiv.org/abs/1811.02084"
             class="btn btn-default">Paper</a>
             <a href="/papers/ShazeerEtAl2018_poster.pdf"
             class="btn btn-default">Poster</a>
             <a href="https://github.com/tensorflow/mesh"
             class="btn btn-default">Code</a>
           </div>
          </p>
          <p>
           <strong>Image Transformer</strong><br>
           An image autoregressive model using only attention.
           <br>
           Niki Parmar, Ashish Vaswani, Jakob Uszkoreit, Lukasz Kaiser, Noam
           Shazeer, Alexander Ku, <strong>Dustin Tran</strong><br>
           <em>International Conference on Machine Learning</em>, 2018
           <div class="btn-group-xs">
             <a href="https://arxiv.org/abs/1802.05751"
             class="btn btn-default">Paper</a>
             <a href="/papers/ParmarVaswaniUszkoreitKaiserShazeerKuTran2018_poster.pdf"
             class="btn btn-default">Poster</a>
             <a href="https://github.com/tensorflow/tensor2tensor"
             class="btn btn-default">Code</a>
           </div>
          </p>
          <p>
           <strong>Implicit causal models for genome-wide association
           studies</strong><br>
           Generative models applied to causality in genomics.
           <br>
           <strong>Dustin Tran</strong>, David M. Blei<br>
           <em>International Conference on Learning Representations</em>, 2018
           <div class="btn-group-xs">
             <a href="https://arxiv.org/abs/1710.10742"
             class="btn btn-default">Paper</a>
             <a href="/papers/TranBlei2018_poster.pdf"
             class="btn btn-default">Poster</a>
             <a href="https://www.youtube.com/watch?v=gi2jZ_bVJuA&index=6&list=PL6_fD5q0zQxshmFJCSBaA5Jglf62Ct4Vm"
             class="btn btn-default">Video</a>
             <a href="/talks/Tran_Genomics.pdf"
             class="btn btn-default">Slides</a>
           </div>
          </p>
          <p>
           <strong>Flipout: Efficient pseudo-independent weight perturbations
           on mini-batches</strong><br>
           How to make weight perturbations in evolution strategies and
           variational BNNs as mini-batch-friendly as activation perturbations
           in dropout and batch norm.
           <br>
           Yeming Wen, Paul Vicol, Jimmy Ba, <strong>Dustin Tran</strong>,
           Roger Grosse<br>
           <em>International Conference on Learning Representations</em>, 2018
           <div class="btn-group-xs">
             <a href="https://arxiv.org/abs/1803.04386"
             class="btn btn-default">Paper</a>
             <a href="https://github.com/tensorflow/tensor2tensor"
             class="btn btn-default">Code</a>
           </div>
          </p>
          <h3>2017</h3>
          <p>
            <strong>Hierarchical implicit models and likelihood-free
            variational inference</strong><br>
            Combining the idea of implicit densities with hierarchical Bayesian
            modeling and deep neural networks.
            <br>
            <strong>Dustin Tran</strong>, Rajesh Ranganath, David M.
            Blei<br>
            <em>Neural Information Processing Systems</em>, 2017
            <div class="btn-group-xs">
              <a href="/papers/TranRanganathBlei2017.pdf"
              class="btn btn-default">Paper</a>
              <a href="/papers/TranRanganathBlei2017_poster.pdf"
              class="btn btn-default">Poster</a>
              <a href="http://dustintran.com/blog/deep-and-hierarchical-implicit-models"
              class="btn btn-default">Blog Article</a>
            </div>
          </p>
          <p>
            <strong>Variational inference via $\chi$-upper bound
            minimization</strong><br>
            Overdispersed approximations and upper bounding
            the model evidence.
            <br>
            Adji B. Dieng, <strong>Dustin Tran</strong>, Rajesh
            Ranganath, John Paisley, David M. Blei<br>
            <em>Neural Information Processing Systems</em>, 2017
            <div class="btn-group-xs">
              <a href="/papers/BoussoTranRanganathPaisleyBlei2017.pdf"
              class="btn btn-default">Paper</a>
              <a href="https://github.com/blei-lab/edward"
              class="btn btn-default">Code</a>
            </div>
          </p>
          <p>
            <strong>Comment, "Fast approximate inference for
            arbitrarily large semiparametric regression models via
            message passing"</strong><br>
            The role of message passing in automated inference.
            <br>
            <strong>Dustin Tran</strong>, David M. Blei<br>
            <em>Journal of the American Statistical Association</em>,
            112(517):156–158, 2017
            <div class="btn-group-xs">
              <a href="http://arxiv.org/abs/1609.05615"
              class="btn btn-default">Paper</a>
              <a href="http://dustintran.com/blog/discussion-of-fast-approximate-inference"
              class="btn btn-default">Blog Article</a>
            </div>
          </p>
          <p>
            <strong>Automatic differentiation variational inference</strong><br>
            An automated tool for black box variational inference,
            available in Stan.
            <br>
            Alp Kucukelbir, <strong>Dustin Tran</strong>, Rajesh Ranganath,
            Andrew Gelman, David M. Blei<br>
            <em>Journal of Machine Learning Research</em>, 18(14):1–45, 2017
            <div class="btn-group-xs">
              <a href="/papers/KucukelbirTranRanganathGelmanBlei2017.pdf"
              class="btn btn-default">Paper</a>
              <a href="https://github.com/stan-dev/stan"
              class="btn btn-default">Code</a>
              <a href="/talks/Tran_Automating.pdf"
              class="btn btn-default">Slides</a>
            </div>
          </p>
          <p>
            <strong>Deep probabilistic programming</strong><br>
            How to build a language with rich compositionality for
            modeling and inference.
            <br>
            <strong>Dustin Tran</strong>, Matthew D. Hoffman, Rif A.
            Saurous, Eugene Brevdo, Kevin Murphy, David M. Blei<br>
            <em>International Conference on Learning Representations</em>, 2017
            <div class="btn-group-xs">
              <a href="/papers/TranHoffmanSaurousBrevdoMurphyBlei2017.pdf"
              class="btn btn-default">Paper</a>
              <a href="http://edwardlib.org/iclr2017"
              class="btn btn-default">Website</a>
              <a href="/papers/TranHoffmanMurphyBrevdoSaurousBlei2017_poster.pdf"
              class="btn btn-default">Poster</a>
              <a href="/talks/Tran_Edward.pdf"
              class="btn btn-default">Slides</a>
            </div>
          </p>
          <h3>2016</h3>
          <p>
            <strong>Operator variational inference</strong><br>
            How to formalize computational and statistical tradeoffs in variational inference.
            <br>
            Rajesh Ranganath, Jaan Altosaar, <strong>Dustin
            Tran</strong>, and David M. Blei<br>
            <em>Neural Information Processing Systems</em>, 2016
            <div class="btn-group-xs">
              <a href="/papers/RanganathAltosaarTranBlei2016.pdf"
              class="btn btn-default">Paper</a>
              <a href="/papers/RanganathAltosaarTranBlei2016_poster.pdf"
              class="btn btn-default">Poster</a>
            </div>
          </p>
          <p>
            <strong>Hierarchical variational models</strong><br>
            A Bayesian formalism for constructing expressive
            variational families.
            <br>
            Rajesh Ranganath, <strong>Dustin Tran</strong>, David M.
            Blei<br>
            <em>International Conference on Machine Learning</em>, 2016
            <div class="btn-group-xs">
              <a href="/papers/RanganathTranBlei2016.pdf"
              class="btn btn-default">Paper</a>
              <a href="/papers/RanganathTranBlei2016_poster.pdf"
              class="btn btn-default">Poster</a>
            </div>
          </p>
          <p>
            <strong>Spectral M-estimation with application to hidden
            Markov models</strong><br>
            Applying M-estimation for sample efficiency and robustness
            in moment-based estimators.
            <br>
            <strong>Dustin Tran</strong>, Minjae Kim, Finale Doshi-Velez<br>
            <em>Artificial Intelligence and Statistics</em>, 2016
            <div class="btn-group-xs">
              <a href="/papers/TranKimDoshi-Velez2016.pdf"
              class="btn btn-default">Paper</a>
            </div>
          </p>
          <p>
            <strong>Towards stability and optimality in stochastic gradient
            descent</strong><br>
            A stochastic gradient method combining numerical stability
            and statistical efficiency.
            <br>
            Panos Toulis, <strong>Dustin Tran</strong>, Edoardo M.
            Airoldi<br>
            <em>Artificial Intelligence and Statistics</em>, 2016
            <div class="btn-group-xs">
              <a href="/papers/ToulisTranAiroldi2016.pdf"
              class="btn btn-default">Paper</a>
              <a href="/papers/ToulisTranAiroldi2016_poster.pdf"
              class="btn btn-default">Poster</a>
              <a href="https://github.com/airoldilab/sgd"
              class="btn btn-default">Code</a>
            </div>
          </p>
          <p>
            <strong>The variational Gaussian process</strong><br>
            A powerful variational model that can universally
            approximate any posterior.
            <br>
            <strong>Dustin Tran</strong>, Rajesh Ranganath, David M.
            Blei<br>
            <em>International Conference on Learning Representations</em>, 2016
            <div class="btn-group-xs">
              <a href="/papers/TranRanganathBlei2016.pdf"
              class="btn btn-default">Paper</a>
              <a href="/talks/Tran_Variational.pdf"
              class="btn btn-default">Slides</a>
            </div>
          </p>
          <h3>2015</h3>
          <p>
            <strong>Copula variational inference</strong><br>
            Posterior approximations using copulas, which find
            meaningful dependence between latent variables.
            <br>
            <strong>Dustin Tran</strong>, David M. Blei, Edoardo M.
            Airoldi<br>
            <em>Neural Information Processing Systems</em>, 2015
            <div class="btn-group-xs">
              <a href="/papers/TranBleiAiroldi2015.pdf"
              class="btn btn-default">Paper</a>
              <a href="/papers/TranBleiAiroldi2015_poster.pdf"
              class="btn btn-default">Poster</a>
            </div>
          </p>
        </div>

      </div>

    </div>

    <hr>

    <footer>
    &nbsp;
    </footer>

  </div>

  <!-- JavaScript -->
  <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.1/jquery.min.js"></script>
  <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.1/js/bootstrap.min.js"></script>
  <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {
        inlineMath: [ ['$','$'] ],
        processEscapes: true
      }
    });
  </script>
  <script type="text/javascript"
     src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
  </script>
  <script type="text/javascript" src="/js/main.js"></script>
</body>
</html>


